\section{Methods}

\subsection{Network notations}
Let's consider a location and the resulting interactions of this sampling. We consider a bipartite network with r resources species and c consumer species. In this case, the resources and consumers do not imply a prédation. It can either be plant/pollinators, host/parasitism, or else as long as the network is bipartite. 

Let $Y$ be the $r\times c$ matrix of interactions such that $\textrm{Y} = [y_{ij}]$. With $y_{ij}$ the number of interactions between i and j was observed.

$r=\textrm{P1}_r =[p_{1+}, ..., p_{r+}]^\intercal$

$c=\textrm{P1}_c=[p_{+1}, ..., p_{+c}]^\intercal$

matrices vecteur en gras droit majuscule
vecteur vecteur en gras droit minuscule

$p_{i+}=\sum_{j=1}^{c}$ and $p_{+j}=\sum_{i=1}^{r}$ are the marginal sums for rows and columns.




$m\times n$ contingency table $A = [a_{ij}]$ 

\paragraph{A small introduction about the history}




\subsection{Correspondence analysis}

Introduction about CA

Correspondence analysis (CA), also known as reciprocal averaging is a multivariate statistical technique  primarily developed to analyze two-way contingency tables (for example the eye color's distribution against the hair color). It enables us to visualize the table in a lower dimensional space and put in evidence the relation between the rows and the columns of the table.

It can be viewed as a three-step process. The first is obtaining the standardized residuals by computing the distances to the null (independence) model. The second one uses Singular Value Decomposition to get the axes containing the maximum variance. Finally, we select the axes holding the most information to reduce the dimensionality of the data and visualize these components in a lower dimensionality space using the coordinates obtained with the singular value decomposition.


Let's consider a $r \times c$ two-way contingency matrix $\mathbf{Y} = [y_{ij}]$ such that $r\geq c$ and let $\mathbf{P}$ be the matrix of proportions of $\mathbf{Y}$ represented by $y_{ij}$ such that:
$$
\mathbf{P} = \left[ \frac{y_{ij}}{\sum_{i=1}^{r} \sum_{j=1}^{c} y_{ij}} \right]
$$

The relative weights (marginal proportions ie. sum of the columns and sum of the rows) of the row and columns of $\mathbf{P}$ are defined respectively as: 
$$
    \mathbf{w}_c = \mathbf{P}1 \quad \text{and} \quad \mathbf{w}_r = 1^\intercal\mathbf{P}
$$

where \(\mathbf{1}\) is a vector of ones of appropriate dimension.
These weights are then transformed into diagonal matrices: 
$$
    \mathbf{W}_r = \text{diag}\left(\frac{1}{\sqrt{\mathbf{w}_r}}\right) \quad \text{and} \quad \mathbf{W}_c = \text{diag}\left(\frac{1}{\sqrt{\mathbf{w}_c}}\right)
$$

\subsubsection{1: Contribution to $\chi^2$ / distance to null model}

Let $\mathbf{P}_0$ be the $r\times c$ expected matrix under the null hypothesis that no relationship exists between the rows and the columns. We define $\mathbf{P}_0$ as:
$$
    \mathbf{P}_0 = \mathbf{w}_r \mathbf{w}_c^\intercal
$$

To compute the standardized residuals of $\mathbf{P}$, we first look at the difference between $\mathbf{P}$ and the null model $\mathbf{P}_0$ and then double-scale it by the diagonal matrices $\mathbf{W}_r$ and $\mathbf{W}_c$. 
$$
    \mathbf{S} = \mathbf{W}_r (\mathbf{P} - \mathbf{P}_0) \mathbf{W}_c
$$

\subsubsection{2: Single Value Decomposition}

Singular value decomposition (SVD) is a generalization of eigendecomposition to rectangular matrices. It is widely used in fields like informatics for applications such as image compression. It enables the decomposition of the matrix into a sum of axes weighted by singular values, indicating the variance explained by each axis.

SVD enables the decomposition of a matrix such as the previous one under the form: 
$$
    \mathbf{S} = \mathbf{U}_{(r\times c)} \Sigma_{(diagonal, c\times c)} \mathbf{V}_{(c \times c)}^\intercal \Leftrightarrow \mathbf{S} = \sum_i \sigma_i \mathbf{U}_i \mathbf{V}_i^\intercal
$$

where:
\begin{itemize}
    \item $\mathbf{U}$ and $\mathbf{V}$ are orthogonal left and right singular vectors such as $\mathbf{U}^\intercal\mathbf{U} = \mathbf{V}^\intercal\mathbf{V} = \mathbf{I}$.
    \item  $\Sigma$ is a diagonal matrix $\mathbf{D}_{\sigma_i}$ with $\sigma_i \in \mathbb{R}^+$, which are the singular values of $\mathbf{S}$.
\end{itemize}


\paragraph{3: Coordinates}

To visualize the result, an additional step is needed to transform the singular vectors into coordinates that preserve the $\chi^2$ distances. The principal coordinates for the rows of $\mathbf{P}$ are computed as :
$$
    \mathbf{F}_r = \mathbf{W}_r \mathbf{U} \Sigma
$$

BESOIN D'EXPLICATIONS POUR LA PAGE WIKIPEDIA

Similarly, the principal coordinates for the columns are computed as:
$$
    \mathbf{F}_c = \mathbf{W}_c \mathbf{V} \Sigma
$$ 
PAS VRAIMENT FINI, À REVOIR AVEC STEPHANE OU LISA

comment caluler le scores (poids x racine de lambda): la partie sur les coordonées avec les l1, c1
*******************************


lier les notations avec ce que j'ai fait sur les réseaux



\subsection{Foucart Correspondance analysis}

Foucart Correspondance Analysis (foucart COA) is a method used to analyse a serie of contingency tables (Pavoine et al. 2007) crossing the same two variables (in our case consumers and resources).
It is divided in two steps, first unravel the common structure and then the intra-structure of each contingency table.

Let be $\mathbf{Y}_1, \ldots, \mathbf{Y}_k, \ldots, \mathbf{Y}_K$ be $K$ contingency tables with the same $I$ rows and $J$ columns: $\mathbf{Y}_k = [y_{ij}^k]$. 
Let $(\mathbf{X}_1, \mathbf{D}_J^1, \mathbf{D}_I^1), \ldots, (\mathbf{X}_1, \mathbf{D}_J^k, \mathbf{D}_I^k), \ldots, (\mathbf{X}_1, \mathbf{D}_J^K, \mathbf{D}_I^K)$ be the $\mathbf{K}$ associated triplets.

\paragraph{1: Common structure}

In the first instance, we compute a regular CA as previously on the agglomeration of the contingency tables.
Let $\mathbf{C}^k = \left[ \frac{y_{ij}^k}{\sum_{i=1}^{r} \sum_{j=1}^{c} y_{ij}^k} \right]$ be the frequency table associated to the $k^{th}$ contingency table $\mathbf{Y}_k$ where $\sum_{i=1}^{r} \sum_{j=1}^{c} y_{ij}^k$ is the grand total of the contingency table $\mathbf{Y}_k$.
We define the common table $\mathbf{C}$ as:
$$
    \mathbf{C} = \frac{1}{K} \sum_{k=1}^K \mathbf{C}^k = \left[ \frac{1}{K}\sum_{k=1}^{K}\frac{y_{ij}^k}{\sum_{i=1}^{r} \sum_{j=1}^{c} y_{ij}^k} \right]
$$
and then compute the CA on the matrix $\mathbf{C}$.

\paragraph{2: Intra-structure}

Next, we project the rows and columns of each contingency table onto the axes of the analysis of the average table.

The  projection of the columns is obtained by: $\left( \mathbf{C}^k (\mathbf{D}_J^k)^{-1} \right)^\intercal\mathbf{B}$
The projection of the rows is obtained by: $\left( (\mathbf{D}_I^k)^{-1}\mathbf{C}^k \right) \mathbf{A}$



\subsection{Simulation}

Realistic interaction network generation is a complex task and many ways exist to generate some such as random geometric graphs or dendritic networks. To validate the method, we must have full knowledge of the input used to create the networks and generate many networks.

The simulation framework is based on Lisa Nickvert's thesis, which is based on Fründ et al 2016, Benadi et al 2022, Dray and Legrendre 2008.

For the simulation, we assume that the proxy of the relative abundances is the frequency of the observed interaction for a given species. We also assume that the interactions are solely based on a mixed effect of the trait matching and the abundance. We can be understood as the probability of two species encountering, which is the product of the abundance, time the probability of these two species interacting together based on their trait matching.

Also, using a bipartite network assumes that there is no interaction intra-group but only inter-groups. It implies competition, facilitation, and spatial exclusion.




\subsubsection{a) Traits generation}

Interactions are shaped by trait matching in ecosystems (cite the work). To model these interactions, we need to generate traits for consumers and resources.

Parler d'autre façons de simuler des réseaux d'interactions réalistes et pourquoi est ce que l'on a besoin de créer notre propre model pour générer des réseaux.

We simulate two traits for both the consumer and resource species. We define $\mathbf{T}^c = [t^c_{jk}]$ $(c \times 2)$ where $j$ is the number of consumer species and we similarly have $\mathbf{T}^r = [t^r_{ik}]$ $(r \times 2)$ where $i$ corresponds to the number of resource species.

The mean of the first trait is uniformly distributed between 0 and 1 for both consumers and resources. For the second trait, the span of the gradient is smaller such that it has a lesser  driving weight on the matching.
For the consumer, each trait distribution is characterized by a mean (theoretical optimal trait value of the species) and a variance (indicating the degree of specialization or generalism).

The trait matching does not have to be well-defined physical traits, such as the bill length or the fruit size. Traits can composite multiple factors, including subjective ones like taste. For instance, the taste gradient of a fruit could range from sour/bitter to sweet. On the consumer side, the species would have a corresponding position to their taste and tolerance or intra-species variability.

The traits follow a normal distribution, with the means uniformly distributed between 0 and 1 and checker le range de sigma. The probability density function (PDF) for a resource with a trait $t_j$ and a consumer with an optimum at $t_i^r$ and a variance of $s_i^r$ is given by:

$$
    \mathbf{PDF:} \quad \frac{1}{\sigma_i\sqrt{2\pi}} \exp\ -\left(\frac{t_j^c-t_i^r}{2s_i^r}\right)^{\!2}\
$$

\subsubsection{b) Interaction probability based on trait matching}

To compute the interaction probability solely based on trait matching, we assume that the interaction niche of the consumers follows a bivariate normal distribution defined by their traits. The likelihood of an interaction between a consumer and a resource to occur hence depends on the proximity of their optimums, which gives a notion of compatibility and the tolerance of the consumer's trait.

Let $\mathbf{M} = [m_{ij}]$ be the trait-matching matrix, where $m_{ij}$ is the interaction probablity between the consumer species $i$ and the resource $j$. This probability is given by:

$$
    \mathbf{M} = [m_{ij}]=\frac{1}{2\pi s_{j1}s_{j2}} \mathbf{exp}\left(-\frac{(t^c_{j1} - t^r_{i1})^2}{2s^2_{j1}} - \frac{(t^c_{j2} - t^r_{i2})^2}{2s^2_{j2}}\right)
$$

where:
\begin{itemize}
    \item $t^r \text{ and }t^c$ are the traits optimums
    \item $s^2$ is the tolerance
\end{itemize}

Cependant ici on dirait que ce n'est que la pdf de la fonction normale de l'un $\times$ celui de l'autre, je ne sais pas si c'est bien ça.




\subsubsection{c) Abundances and environmental distribution}



In this section, we adopt the  Hutchinsonian definition of the niche, which describes a species as a position of the species in an $n$-dimensional gradient, with in our case $n=1$ to keep the simulation simple.

We define an environmental gradient which can be interpreted as an environmental factor such as the humidity, soil resources availability, sun exposure, temperature, and the density of the environment. For example, it could be the altitude in the alpine environment, which is a proxy for global warming. Or it can be the time and hence the seasonality fluctuations for example.

Similarly to the trait, each species is assigned a position and a tolerance on this environmental gradient that we will respectively call $\mathbf{E}^c = e_{jk}^c$ and $\mathbf{E}^r = e_{ik}^r$ for the consumers and resources.

To compute the number of individuals observed in a given quadrant during the observation time, we first compute the theoretical abundance of each species based on their position and a random factor, supposing that the niche distribution follows a normal variable.
The abundance of $th\_a_{ix}$ of the species $i$ at the position $x$ on the gradient is given by:

$$
    th\_a_{ix} = N_i \cdot \frac{1}{\sigma_i\sqrt{2\pi}} exp \left( -\frac{(x-\mu_i)^2}{2\sigma_i^2} \right)
$$

where:
\begin{itemize}
    \item $N_i$ is a scaling factor representing the total population size proper to each species
    \item $x$ is the environmental position on the gradient
    \item $\mu_i$ is the niche optimum position of the species and $\sigma_i^2$ is the tolerance of the species
\end{itemize}

Then we simulate the actual number of individuals observed during the sampling time using a Poisson process to take into account the stochasticity of the species presence. The observation count $n_{ix}^c$ for the species $i$ in the quadrat $x$ can be modeled as:

$$
    n_{ix}^c \thicksim Poisson(th\_a_{ix})
$$

\subsubsection{d) Interaction probability based on population size}

We assume that, similar to how the speed of a reaction is proportional to the product of the reactant concentration, the number of potential interactions in the network is proportional to the number of individuals. Therefore, for each network, we multiply the population size of both consumers and resources. 
Hence, we define the neutral effect matrix/ mean-field matrix $\mathbf{A}$ as : 

$$
    \mathbf{A} = [a_{ij}] = a^r a^{c\intercal}
$$

\subsubsection{e) Integration of the trait matching and mean field}

The main assumption of this model is that species interactions are driven by both the relative abundance of the species and their compatibility regarding trait matching.

Depending on the weight given to trait-matching and mean-field effects, we define the mixed effect probability matrix $\mathbf{P}$ as: 

$$
    \mathbf{P} = p^*_{ij} = \frac{{m_{i\mid j}}^\delta a_{ij}}{\sum_{i=1}^{r} \sum_{j=1}^{c}a_{ij}}
$$
    
where:
\begin{itemize}
\item  $\delta$ is a parameter that controls the weight given to trait matching compared to the neutral effect.
\item  $m_{i|j}$ represents the compatibility or matching score between species \(i\) and \(j\).
\item  $a_{ij}$ is the interaction term reflecting the relative abundance of species \(i\) and \(j\).
\item  $\sum_{i=1}^{r} \sum_{j=1}^{c}a_{ij}$ is a normalization constant ensuring that the elements of \(\mathbf{P}^*\) sum to 1.
\end{itemize}

The parameter $\delta$ allows the adjustment of the influence of trait matching in the model. When $\delta = 0$, the models relies only on the mean-filed (neutral) effect, meaning that there are no preferences, and as $\delta$ increases, the trait matching becomes main the driving factor of the interactions.



\subsubsection{f) Sampling of the interactions based on the previous computed probability}

To account for the bias in sampling effort of the observed interaction, we sample $n_{inter}$ interactions using a multinomial distribution based on the probability matrix $\mathbf{P}$. The multinomial distribution with $\kappa = r \times c$ outcomes, corresponding to the set of all the possible combinations of interactions.

The interaction counts are defined in the matrix $\mathbf{Z}$ as:

$$
    \mathbf{Z} \sim \mathcal{M}_{\kappa = rc}(n = n_\text{inter}, p = \mathbf{P})
$$

where:
\begin{itemize}
    \item $\mathbf{P}$ is the previously computed probability matrix of interactions.
    \item  $n_{\text{inter}}$ is the total number of sampled interactions.
    \item  $\mathcal{M}_{\kappa}$ denotes the multinomial distribution with \(\kappa\) possible outcomes.
\end{itemize}



Ajouter mes contribution et expliquer le mieux des deux